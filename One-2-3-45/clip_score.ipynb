{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7890'\n",
    "# os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7890'\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from scipy.spatial import cKDTree\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算 Clip 相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
    "\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path):\n",
    "    # Load the image from the specified path\n",
    "    image = Image.open(image_path)\n",
    "    # Apply the CLIP preprocessing to the image\n",
    "    image = processor(images=image)\n",
    "    # Return the preprocessed image\n",
    "    return image\n",
    "\n",
    "\n",
    "def clip_img_score (img1_path,img2_path):\n",
    "    # Load the two images and preprocess them for CLIP\n",
    "    image_a = load_and_preprocess_image(img1_path)[\"pixel_values\"]\n",
    "    image_b = load_and_preprocess_image(img2_path)[\"pixel_values\"]\n",
    "\n",
    "    # Calculate the embeddings for the images using the CLIP model\n",
    "    with torch.no_grad():\n",
    "        embedding_a = model.get_image_features(torch.tensor(np.array(image_a)).to(\"cuda\"))\n",
    "        embedding_b = model.get_image_features(torch.tensor(np.array(image_b)).to(\"cuda\"))\n",
    "\n",
    "    # Calculate the cosine similarity between the embeddings\n",
    "    similarity_score = torch.nn.functional.cosine_similarity(embedding_a, embedding_b)\n",
    "    return similarity_score.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "for model_name in tqdm(os.listdir(\"/home/ljr/Machine-Learning-Project/val/gt\")):\n",
    "    print(model_name)\n",
    "    res[model_name] = [0.0, 0.0]\n",
    "    for i in range(8):\n",
    "        for j in range(4):\n",
    "            res[model_name][0] += clip_img_score(f\"/home/ljr/Machine-Learning-Project/val/gt/{model_name}/view_{i}_{j}_10.png\", f\"/home/ljr/Machine-Learning-Project/val/val_finetune_rendered/{model_name}/view_{i}_{j}_10.png\")\n",
    "            res[model_name][1] += clip_img_score(f\"/home/ljr/Machine-Learning-Project/val/gt/{model_name}/view_{i}_{j}_10.png\", f\"/home/ljr/Machine-Learning-Project/val/val_zeroshot_rendered/{model_name}/view_{i}_{j}_10.png\")\n",
    "    res[model_name][0] /= 32\n",
    "    res[model_name][1] /= 32\n",
    "    print(res[model_name])\n",
    "\n",
    "# 将结果写入txt文件\n",
    "with open('clip_scores.txt', 'w') as f:\n",
    "    for model_name, scores in res.items():\n",
    "        f.write(f\"{model_name}: \\nfinetune={scores[0]:.5f}, zeroshot={scores[1]:.5f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将结果转换为DataFrame格式\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame(res).T\n",
    "df.columns = ['finetune', 'zeroshot']\n",
    "\n",
    "# 设置图形大小\n",
    "plt.figure(figsize=(15, 6), dpi=300)\n",
    "\n",
    "# 绘制直方图\n",
    "x = np.arange(len(df.index))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, df['finetune'], width, label='Finetune')\n",
    "plt.bar(x + width/2, df['zeroshot'], width, label='Zeroshot')\n",
    "\n",
    "# 设置图形属性\n",
    "plt.xlabel('model name')\n",
    "plt.ylabel('CLIP score')\n",
    "plt.title('Finetune vs Zeroshot CLIP score')\n",
    "plt.xticks(x, df.index, rotation=45, ha='right', fontsize=8)\n",
    "plt.legend()\n",
    "\n",
    "# 调整布局避免标签重叠\n",
    "plt.tight_layout()\n",
    "\n",
    "# 显示图形\n",
    "plt.show()\n",
    "\n",
    "# 计算finetune和zeroshot的平均值\n",
    "finetune_mean = df['finetune'].mean()\n",
    "zeroshot_mean = df['zeroshot'].mean()\n",
    "\n",
    "print(f\"Finetune平均值: {finetune_mean:.5f}\")\n",
    "print(f\"Zeroshot平均值: {zeroshot_mean:.5f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "with open('/home/ljr/Machine-Learning-Project/clip_scores_1.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# 解析数据\n",
    "finetune_scores = []\n",
    "zeroshot_scores = []\n",
    "for line in lines:\n",
    "    if 'finetune' in line:\n",
    "        parts = line.split(': ')\n",
    "        scores = parts[1].split(', ')\n",
    "        finetune_scores.append(float(scores[0].split('=')[1]))\n",
    "        zeroshot_scores.append(float(scores[1].split('=')[1]))\n",
    "\n",
    "# 创建对比图\n",
    "plt.figure(figsize=(12, 6), dpi=100)\n",
    "plt.plot(finetune_scores, label='Finetune', marker='o', color='#1f77b4', linewidth=2, markersize=6)\n",
    "plt.plot(zeroshot_scores, label='Zeroshot', marker='x', color='#ff7f0e', linewidth=2, markersize=6)\n",
    "\n",
    "# 设置图形属性\n",
    "plt.xlabel('Sample Index', fontsize=12)\n",
    "plt.ylabel('CLIP Score', fontsize=12)\n",
    "plt.title('CLIP Score Comparison: Finetune vs Zeroshot', fontsize=14, pad=20)\n",
    "plt.legend(fontsize=12, loc='upper right')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# 调整刻度字体\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "# 调整布局\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算 F-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import trimesh\n",
    "from scipy.spatial import cKDTree\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_mesh(file_path):\n",
    "    \"\"\"加载3D模型文件（支持glb和obj格式）\"\"\"\n",
    "    if file_path.endswith('.glb'):\n",
    "        scene = trimesh.load(file_path)\n",
    "        if isinstance(scene, trimesh.Scene):\n",
    "            meshes = []\n",
    "            for g in scene.geometry.values():\n",
    "                if isinstance(g, trimesh.Trimesh):\n",
    "                    meshes.append(g)\n",
    "                elif hasattr(g, 'vertices') and hasattr(g, 'faces'):\n",
    "                    meshes.append(trimesh.Trimesh(vertices=g.vertices, faces=g.faces))\n",
    "            \n",
    "            if not meshes:\n",
    "                raise ValueError(f\"No valid mesh found in {file_path}\")\n",
    "            mesh = trimesh.util.concatenate(meshes)\n",
    "        else:\n",
    "            mesh = scene\n",
    "            \n",
    "        vertices = np.array(mesh.vertices)\n",
    "        faces = np.array(mesh.faces)\n",
    "        o3d_mesh = o3d.geometry.TriangleMesh()\n",
    "        o3d_mesh.vertices = o3d.utility.Vector3dVector(vertices)\n",
    "        o3d_mesh.triangles = o3d.utility.Vector3iVector(faces)\n",
    "    else:\n",
    "        o3d_mesh = o3d.io.read_triangle_mesh(file_path)\n",
    "    \n",
    "    if not o3d_mesh.has_vertices():\n",
    "        raise ValueError(f\"Loaded mesh has no vertices: {file_path}\")\n",
    "    \n",
    "    return o3d_mesh\n",
    "\n",
    "def normalize_points(points):\n",
    "    \"\"\"归一化点云到单位球内\"\"\"\n",
    "    centroid = np.mean(points, axis=0)\n",
    "    points = points - centroid\n",
    "    max_dist = np.max(np.sqrt(np.sum(points ** 2, axis=1)))\n",
    "    points = points / max_dist\n",
    "    return points\n",
    "\n",
    "def align_point_clouds(pred_points, gt_points):\n",
    "    \"\"\"对齐两个点云\"\"\"\n",
    "    pred_points = normalize_points(pred_points)\n",
    "    gt_points = normalize_points(gt_points)\n",
    "    \n",
    "    pred_pcd = o3d.geometry.PointCloud()\n",
    "    pred_pcd.points = o3d.utility.Vector3dVector(pred_points)\n",
    "    gt_pcd = o3d.geometry.PointCloud()\n",
    "    gt_pcd.points = o3d.utility.Vector3dVector(gt_points)\n",
    "    \n",
    "    pred_pcd.estimate_normals()\n",
    "    gt_pcd.estimate_normals()\n",
    "    \n",
    "    reg = o3d.pipelines.registration.registration_icp(\n",
    "        pred_pcd, gt_pcd,\n",
    "        max_correspondence_distance=0.1,\n",
    "        estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "        criteria=o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=50)\n",
    "    )\n",
    "    \n",
    "    pred_aligned = pred_pcd.transform(reg.transformation)\n",
    "    return np.asarray(pred_aligned.points)\n",
    "\n",
    "def compute_f_score(pred_points, gt_points, threshold=0.05):\n",
    "    \"\"\"计算F-score\"\"\"\n",
    "    pred_tree = cKDTree(pred_points)\n",
    "    gt_tree = cKDTree(gt_points)\n",
    "    \n",
    "    pred_to_gt_dist, _ = gt_tree.query(pred_points)\n",
    "    gt_to_pred_dist, _ = pred_tree.query(gt_points)\n",
    "    \n",
    "    precision = np.mean(pred_to_gt_dist < threshold)\n",
    "    recall = np.mean(gt_to_pred_dist < threshold)\n",
    "    f_score = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "    \n",
    "    return precision, recall, f_score\n",
    "\n",
    "def compute_fscore(gt_path, pred_path, n_points=5000):\n",
    "    \"\"\"计算两个3D模型之间的F-score\"\"\"\n",
    "    try:\n",
    "        gt_mesh = load_mesh(gt_path)\n",
    "        pred_mesh = load_mesh(pred_path)\n",
    "        \n",
    "        gt_pcd = gt_mesh.sample_points_uniformly(n_points)\n",
    "        pred_pcd = pred_mesh.sample_points_uniformly(n_points)\n",
    "        \n",
    "        gt_points = np.asarray(gt_pcd.points)\n",
    "        pred_points = np.asarray(pred_pcd.points)\n",
    "        \n",
    "        pred_aligned = align_point_clouds(pred_points, gt_points)\n",
    "        \n",
    "        precision, recall, f_score = compute_f_score(pred_aligned, gt_points, threshold=0.05)\n",
    "        return precision, recall, f_score\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {gt_path} and {pred_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = {'finetune': [], 'zeroshot': []}\n",
    "    \n",
    "    for model_name in tqdm(os.listdir(\"/home/ljr/Machine-Learning-Project/val/gt\")):\n",
    "        gt_path = f\"/home/ljr/Machine-Learning-Project/needed_models/{model_name}/{model_name}.glb\"\n",
    "        \n",
    "        if not os.path.exists(gt_path):\n",
    "            print(f\"Skipping {model_name}: GT file not found\")\n",
    "            continue\n",
    "            \n",
    "        pred_paths = {\n",
    "            'finetune': f\"/home/ljr/Machine-Learning-Project/val/val_finetune_rendered/{model_name}/mesh.obj\",\n",
    "            'zeroshot': f\"/home/ljr/Machine-Learning-Project/val/val_zeroshot_rendered/{model_name}/mesh.obj\"\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n处理模型: {model_name}\")\n",
    "        \n",
    "        for method, pred_path in pred_paths.items():\n",
    "            if not os.path.exists(pred_path):\n",
    "                print(f\"Skipping {method} for {model_name}: File not found\")\n",
    "                continue\n",
    "                \n",
    "            scores = compute_fscore(gt_path, pred_path)\n",
    "            if scores:\n",
    "                precision, recall, f_score = scores\n",
    "                results[method].append({\n",
    "                    'model': model_name,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'f_score': f_score\n",
    "                })\n",
    "                \n",
    "                print(f\"\\n{method}评估结果:\")\n",
    "                print(f\"F-score: {f_score:.4f}\")\n",
    "                print(f\"Precision: {precision:.4f}\")\n",
    "                print(f\"Recall: {recall:.4f}\")\n",
    "    \n",
    "    # 计算平均值\n",
    "    for method in ['finetune', 'zeroshot']:\n",
    "        if results[method]:\n",
    "            avg_f_score = np.mean([r['f_score'] for r in results[method]])\n",
    "            avg_precision = np.mean([r['precision'] for r in results[method]])\n",
    "            avg_recall = np.mean([r['recall'] for r in results[method]])\n",
    "            \n",
    "            print(f\"\\n{method}平均结果:\")\n",
    "            print(f\"Average F-score: {avg_f_score:.4f}\")\n",
    "            print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "            print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "\n",
    "    # 将结果保存到文件\n",
    "    with open('fscore_results.txt', 'w') as f:\n",
    "        for method in ['finetune', 'zeroshot']:\n",
    "            f.write(f\"\\n{method}结果:\\n\")\n",
    "            for result in results[method]:\n",
    "                f.write(f\"{result['model']}:\\n\")\n",
    "                f.write(f\"F-score: {result['f_score']:.4f}\\n\")\n",
    "                f.write(f\"Precision: {result['precision']:.4f}\\n\")\n",
    "                f.write(f\"Recall: {result['recall']:.4f}\\n\")\n",
    "                f.write(\"-\" * 50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取结果文件并解析数据\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def parse_results_file(filename):\n",
    "    results = {'finetune': [], 'zeroshot': []}\n",
    "    current_method = None\n",
    "    current_model = None\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "            \n",
    "        if line.endswith('结果:'):\n",
    "            current_method = line.split('结果')[0]\n",
    "            continue\n",
    "            \n",
    "        if line.endswith(':'):\n",
    "            current_model = line[:-1]\n",
    "            continue\n",
    "            \n",
    "        if line.startswith('F-score:'):\n",
    "            f_score = float(line.split(':')[1])\n",
    "            results[current_method].append({\n",
    "                'model': current_model,\n",
    "                'f_score': f_score\n",
    "            })\n",
    "            \n",
    "    return results\n",
    "\n",
    "# 解析结果\n",
    "results = parse_results_file('fscore_results.txt')\n",
    "\n",
    "# 准备绘图数据\n",
    "finetune_models = [r['model'] for r in results['finetune']]\n",
    "finetune_scores = [r['f_score'] for r in results['finetune']]\n",
    "zeroshot_models = [r['model'] for r in results['zeroshot']]\n",
    "zeroshot_scores = [r['f_score'] for r in results['zeroshot']]\n",
    "\n",
    "# 创建柱状图\n",
    "plt.figure(figsize=(12, 6))\n",
    "x = range(len(finetune_models))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar([i - width/2 for i in x], finetune_scores, width, label='微调', color='skyblue')\n",
    "plt.bar([i + width/2 for i in x], zeroshot_scores, width, label='零样本', color='lightcoral')\n",
    "\n",
    "plt.xlabel('模型')\n",
    "plt.ylabel('F-score')\n",
    "plt.title('微调 vs 零样本 F-score 对比')\n",
    "plt.xticks(x, finetune_models, rotation=45)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
